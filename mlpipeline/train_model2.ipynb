{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8c0862b-e605-4ebd-afc1-7ce31eef13c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#import pickle\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "import mlflow\n",
    "\n",
    "from evidently import ColumnMapping\n",
    "from evidently.report import Report\n",
    "from evidently.metrics import ColumnDriftMetric, DatasetDriftMetric, DatasetMissingValuesMetric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc0ca670-971f-4ef0-936e-051bd973b501",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlflow_setup():\n",
    "    TRACKING_URI = \"http://127.0.0.1:5000\"\n",
    "    EXPERIMENT = \"online-course-engagement-prediction-experiment-1\"\n",
    "\n",
    "    mlflow.set_tracking_uri(TRACKING_URI)\n",
    "    mlflow.set_experiment(EXPERIMENT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c1b0869-b226-4810-85b6-1db817333984",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file_path):\n",
    "    df = pd.read_parquet(file_path)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "047dd9e5-2776-4687-b1a8-9c7a7f8c2fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(file_path):\n",
    "    df = read_data(file_path)\n",
    "    df['TimeSpentOnCourse'] = df['TimeSpentOnCourse'].round(2)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01c6f806-a2ff-4f2c-bb28-beb9e6304636",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train(file_path):\n",
    "    df = clean_data(file_path)\n",
    "    df_train = df[:6000]\n",
    "\n",
    "    return df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0122c4e5-9b52-4dd2-aab2-00bb0d85811b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_val(file_path):\n",
    "    df = clean_data(file_path)\n",
    "    df_val = df[6000:]\n",
    "\n",
    "    return df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b79c541e-dd8d-459d-bd17-cf12d57afd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_train(file_path, categorical, numerical, target):    \n",
    "    df_train = get_train(file_path)\n",
    "\n",
    "    df_train.to_parquet('./data/online_course_engagement_train_data.parquet')\n",
    "\n",
    "    train_dict = df_train[categorical + numerical].to_dict(orient='records')\n",
    "\n",
    "    y_train = df_train[target].values\n",
    "\n",
    "    result = {'features':train_dict, 'target':y_train}\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bffee276-f3f4-47eb-8623-73e793f02864",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_val(file_path, categorical, numerical, target):\n",
    "    df_val = get_val(file_path)\n",
    "\n",
    "    df_val.to_parquet('./data/online_course_engagement_val_data.parquet')\n",
    "\n",
    "    val_dict = df_val[categorical + numerical].to_dict(orient='records')\n",
    "\n",
    "    y_val = df_val[target].values\n",
    "\n",
    "    result = {'features':val_dict, 'target':y_val}\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e14c5c5e-9e5c-40c7-a345-07b794332d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def monitor_pipeline(target, numerical, categorical, df_train_mon, df_val_mon):\n",
    "    column_mapping = ColumnMapping(\n",
    "    target=target,\n",
    "    prediction='prediction',\n",
    "    numerical_features=numerical,\n",
    "    categorical_features=categorical\n",
    "    )\n",
    "\n",
    "    report = Report(metrics=[\n",
    "        ColumnDriftMetric(column_name='prediction'),\n",
    "        DatasetDriftMetric(),\n",
    "        DatasetMissingValuesMetric()\n",
    "    ]\n",
    "    )\n",
    "\n",
    "    report.run(reference_data=df_train_mon, current_data=df_val_mon, column_mapping=column_mapping)\n",
    "\n",
    "    result = report.as_dict()\n",
    "\n",
    "    report.save_html(\"./report.html\")\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ebc28328-f786-489e-9f99-cb514af44f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_output(df_train_mon, df_val_mon, train_output, val_output):\n",
    "    df_train_mon.to_parquet(train_output)\n",
    "    df_val_mon.to_parquet(val_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f1d3941-443b-4fd4-b495-c0be25d65351",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pipeline(file_path, train_output, val_output):\n",
    "    print('setting up mlflow')\n",
    "    mlflow_setup()\n",
    "\n",
    "    categorical = ['DeviceType', 'CourseCategory']\n",
    "    numerical = ['TimeSpentOnCourse', 'NumberOfVideosWatched', 'NumberOfQuizzesTaken']\n",
    "    target = 'CourseCompletion'\n",
    "\n",
    "    df_train_mon = pd.DataFrame()\n",
    "    df_val_mon = pd.DataFrame()\n",
    "\n",
    "    with mlflow.start_run():\n",
    "        pipeline = make_pipeline(\n",
    "            DictVectorizer(),\n",
    "            LogisticRegression(max_iter = 10000)\n",
    "        )\n",
    "        \n",
    "        mlflow.set_tag(\"Developer\", \"Agnes\")\n",
    "        mlflow.log_param(\"train-data-path\", \"./data/online_course_engagement_train_data.csv\")\n",
    "        mlflow.log_param(\"valid-data-path\", \"./data/./data/online_course_engagement_val_data.csv\")\n",
    "        mlflow.log_param(\"C\", 1)\n",
    "\n",
    "        print('fetching and preparing train data')\n",
    "        train = prepare_train(file_path, categorical, numerical, target)\n",
    "        train_dict = train['features']\n",
    "        y_train = train['target']\n",
    "\n",
    "        print('fetching and preparing validation data')\n",
    "        val = prepare_val(file_path, categorical, numerical, target)\n",
    "        val_dict = val['features']\n",
    "        y_val = val['target']\n",
    "\n",
    "        print('training LogisticRegression model')\n",
    "        pipeline.fit(train_dict, y_train)\n",
    "\n",
    "        print('making prediction on train and validation datasets')\n",
    "        val_pred = pipeline.predict(val_dict)\n",
    "        train_pred = pipeline.predict(train_dict)\n",
    "\n",
    "        print('calculating rmse for train and validation predictions')\n",
    "        val_rmse = mean_squared_error(y_val, val_pred)\n",
    "        train_rmse = mean_squared_error(y_train, train_pred)\n",
    "\n",
    "        mlflow.log_metric(\"val_rmse\", val_rmse)\n",
    "        mlflow.log_metric(\"train_rmse\", train_rmse)\n",
    "\n",
    "        print('logging model and dictvectorizer as one artifact')\n",
    "        mlflow.sklearn.log_model(pipeline, artifact_path=\"model\")\n",
    "\n",
    "        print('creating new dataframes for monitoring ')\n",
    "        df_val = get_val(file_path)\n",
    "        \n",
    "        df_val_mon[categorical] = df_val[categorical]\n",
    "        df_val_mon[numerical] = df_val[numerical]\n",
    "        df_val_mon[target] = df_val[target]\n",
    "        df_val_mon['prediction'] = val_pred\n",
    "\n",
    "        df_train = get_train(file_path)\n",
    "        df_train_mon[categorical] = df_train[categorical]\n",
    "        df_train_mon[numerical] = df_train[numerical]\n",
    "        df_train_mon[target] = df_train[target]\n",
    "        df_train_mon['prediction'] = train_pred\n",
    "\n",
    "        print('fetching monitoring metrics')\n",
    "        monitoring_metrics = monitor_pipeline(target, numerical, categorical, df_train_mon, df_val_mon)\n",
    "\n",
    "        prediction_drift = monitoring_metrics['metrics'][0]['result']['drift_score']\n",
    "        num_drifted_columns = monitoring_metrics['metrics'][1]['result']['number_of_drifted_columns']\n",
    "        share_missing_values = monitoring_metrics['metrics'][2]['result']['current']['share_of_missing_values']\n",
    "\n",
    "        print('logging monitoring metrics in mlflow')\n",
    "        mlflow.log_metric(\"prediction_drift\", prediction_drift)\n",
    "        mlflow.log_metric(\"num_drifted_columns\", num_drifted_columns)\n",
    "        mlflow.log_metric(\"share_missing_values\", share_missing_values)\n",
    "\n",
    "        print(f'saving monitoring datasets to {train_output} and {val_output}')\n",
    "        write_to_output(df_train_mon, df_val_mon, train_output, val_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "beac539e-f388-4f78-843f-5c8923136d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = './data/online_course_engagement_data.parquet'\n",
    "train_output = './monitoring_data/online_course_engagement_train_data.parquet'\n",
    "val_output = './monitoring_data/online_course_engagement_val_data.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9f3428c-5453-4542-a5e7-36b8d8f60aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running pipeline...\n",
      "setting up mlflow\n",
      "fetching and preparing train data\n",
      "fetching and preparing validation data\n",
      "training LogisticRegression model\n",
      "making prediction on train and validation datasets\n",
      "calculating rmse for train and validation predictions\n",
      "logging model and dictvectorizer as one artifact\n",
      "creating new dataframes for monitoring \n",
      "fetching monitoring metrics\n",
      "logging monitoring metrics in mlflow\n",
      "saving monitoring datasets to ./monitoring_data/online_course_engagement_train_data.parquet and ./monitoring_data/online_course_engagement_val_data.parquet\n"
     ]
    }
   ],
   "source": [
    "print('running pipeline...')\n",
    "run_pipeline(file_path, train_output, val_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fbbb5d-eef8-4019-a855-c5bc2d1bbc5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
